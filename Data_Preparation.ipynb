{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Effect of Biased Gender Data on Face Recognition\n",
    "* **Course:** Neural Networks and Deep Learning (COMP9444) 22T3\n",
    "* **Mentor:** Kunzie Xie\n",
    "* **Team:** Dr. Teeth and the Electric Mayhem\n",
    "* **Members:**\n",
    "    * _Daniel Gotilla_ (z5343046@student.unsw.edu.au)\n",
    "    * _John Conlon_ (z5257381@student.unsw.edu.au)\n",
    "    * _John Pham_ (z3216645@student.unsw.edu.au)\n",
    "    * _Marco Seidenberg_ (z5264260@student.unsw.edu.au)\n",
    "    * _Oscar Feng_ (z5396050@student.unsw.edu.au)\n",
    "\n",
    "## Problem Statement\n",
    "\n",
    "\n",
    "\n",
    "## Data Preparation\n",
    "\n",
    "### Downloading, Concatenating, Validating and Correcting the Original Data\n",
    "\n",
    "We chose to leverage the [UTKFace](https://github.com/aicip/UTKFace) dataset, built by Yang Song and Zhifei Zhang at the [Advanced Imaging and Collaborative Information Processing (AICIP) Lab](https://aicip.github.io/) at [The University of Tennessee, Knoxville (UTK)](http://www.utk.edu/). This dataset contains over 28k face images with annotations for age, gender, and ethnicity and facial landmark coordinates and is available for non-commercial, research purposes.\n",
    "\n",
    "The dataset is provided in separate files (through links to Google Drive):\n",
    "1. **[In-the-wild Faces (1.3GB)](https://drive.google.com/open?id=0BxYys69jI14kSVdWWllDMWhnN2c)** — original images, containing one or more faces. _Not used in our study._\n",
    "2. **[Aligned & Cropped Faces (107MB)](https://drive.google.com/drive/folders/0BxYys69jI14kU0I1YUQyY1ZDRUE?usp=sharing)** — above images, cropped tightly around the faces of each subject; filenames contain the age, gender, race and datetime metadata.\n",
    "3. **[Landmarks (68 points, 12MB)](https://drive.google.com/open?id=0BxYys69jI14kS1lmbW1jbkFHaW8)** — 3 separate text files listing all the aligned/cropped faces (in 2, above) and their associated facial landmarks.\n",
    "\n",
    "Firstly, we need to download the 3 landmark list files from the [UTKFace Google Drive](https://drive.google.com/open?id=0BxYys69jI14kS1lmbW1jbkFHaW8) and copy them to the project directory (without renaming); you will have three files named:\n",
    "* `landmark_list_part1.txt` (9,780 lines)\n",
    "* `landmark_list_part2.txt` (10,719 lines)\n",
    "* `landmark_list_part3.txt` (3,209 lines)\n",
    "\n",
    "We can use the `concatenate_files` function (below) to join the 3 landmark list files into a single file called `landmark_list_concatenated.txt`, deleting the 3 original files in the process. (This function will be used extensively below to consolidate the training, validation and testing datasets.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input files successfully concatenated as landmark_list_concatenated.txt\n"
     ]
    }
   ],
   "source": [
    "from os import remove\n",
    "from random import shuffle, seed\n",
    "\n",
    "def concatenate_files(target: str, files: list[str], *, delete: bool = False, randomise: bool = False,\n",
    "                      randomseed=None):\n",
    "    \"\"\"\n",
    "    Concatenates multiple files, producing a target file and (optionally) randomising lines and/or deleting the input files.\n",
    "\n",
    "    :param target: Name for new (output) file concatenating the input files.\n",
    "    :param files: List of files to concatenate.\n",
    "    :param delete: Should the input files be deleted after concatenation?\n",
    "    :param randomise: Should the lines of the input files be randomised?\n",
    "    :param randomseed: If so, should we use a specific seed value?\n",
    "    :return: No return value but a file with the target name will be created in the current directory.\n",
    "    \"\"\"\n",
    "    lines = []\n",
    "\n",
    "    for name in files:\n",
    "        with open(name, 'r') as f:\n",
    "            for line in f:\n",
    "                lines.append(line)\n",
    "\n",
    "    if randomise:\n",
    "        if seed is not None:\n",
    "            seed(randomseed)\n",
    "        shuffle(lines)\n",
    "\n",
    "    with open(target, \"w\") as new_file:\n",
    "        for line in lines:\n",
    "            new_file.write(line)\n",
    "\n",
    "    if delete:\n",
    "        for name in files:\n",
    "            remove(name)\n",
    "\n",
    "    print(f\"Input files successfully concatenated as\", target)\n",
    "\n",
    "# Concatenating the 3 landmark files into a single one\n",
    "ll_parts = [\"landmark_list_part1.txt\", \"landmark_list_part2.txt\", \"landmark_list_part3.txt\"]\n",
    "concatenate_files(\"landmark_list_concatenated.txt\", files=ll_parts, delete=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The three partial files were substituted by a single, consolidated file named `landmark_list_concatenated.txt` with 23,708 lines, one for each cropped image in the dataset.\n",
    "\n",
    "If you open and examine the file, you'll see something like this:\n",
    "```\n",
    "1_0_2_20161219140530307.jpg -4 71 -4 96 -3 120 -1 144 9 166 28 179 53 186 77 192 100 194 121 191 142 183 161 174 180 161 192 142 195 120 194 97 192 74 16 53 29 39 48 33 68 34 86 40 113 39 129 33 148 32 164 37 175 49 100 59 101 72 101 85 101 99 78 112 89 113 100 116 110 114 120 111 39 62 51 61 61 60 71 65 60 63 50 62 124 64 134 59 144 59 155 62 144 62 134 62 55 137 72 134 87 132 97 133 107 131 120 132 136 133 121 143 109 146 98 147 88 146 72 145 61 138 87 137 97 138 107 136 130 135 108 139 98 140 88 139\n",
    "```\n",
    "\n",
    "Each line follows the pattern `A_G_E_DDDDDDDDTTTTTTTTT.jpg X1 Y1 X2 Y2 … X68 Y68` where:\n",
    "* `A` stands for the subject's age in years (1 to 3 digits);\n",
    "* `G` stands for the subject's gender, where\n",
    "    * 0 is male and\n",
    "    * 1 is female;\n",
    "* `E` stands for the subject's (perceived) ethnicity, where\n",
    "    * 0 is \"white\",\n",
    "    * 1 is \"black\",\n",
    "    * 2 is \"asian\",\n",
    "    * 3 is \"indian\",\n",
    "    * 4 is \"other\";\n",
    "* `DDDDDDDDTTTTTTTTT` stands for the date/time the image was added to the dataset;\n",
    "* `X1 Y1 X2 Y2 … X68 Y68` stands for the 68 (x,y) coordinate pairs for the facial landamarks where\n",
    "    * Pairs 1 through 17 map the contour of the subject's face, from ear to ear around chin;\n",
    "    * Pairs 18 through 22 map the contour of the subject's left eyebrow;\n",
    "    * Pairs 23 through 27 map the contour of the subject's right eyebrow;\n",
    "    * Pairs 28 through 31 map the contour of the line on top of the subject's nose;\n",
    "    * Pairs 32 through 36 map the contour of the bottom part of the subject's nose;\n",
    "    * Pairs 37 through 42 map the contour of the subject's left eye;\n",
    "    * Pairs 43 through 48 map the contour of the subject's right eye;\n",
    "    * Pairs 49 through 60 map the outer contour of the subject's lips;\n",
    "    * Pairs 61 through 68 map the inner contour of the subject's lips;\n",
    "\n",
    "Now let us download the \"Aligned & Cropped Faces\" images from UTKFace's [Google Drive](https://drive.google.com/drive/folders/0BxYys69jI14kU0I1YUQyY1ZDRUE?resourcekey=0-01Pth1hq20K4kuGVkp3oBw)  (you want \"UTKFace.tar.gz\" which sits at about 102MB). Copy the _UTKFace.tar.gz_ file into the project directory and unzip it; you should have a folder named `UTKFace` with 23,708 files. It is a good sign that the number of image files matches the number of lines in `landmark_list_concatenated.txt`, but let us double-check if all the images in the folder are listed in the landmark file and vice-versa. Note that the images are listed in the landmark file with the `.jpg` extension but the actual image files in the `UTKFace` directory use the `.jpg.chip.jpg` extension. The following script accounts for that when validating the dataset:\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing image: 61_3_20170109150557335.jpg.chip.jpg\n",
      "Missing image: 53__0_20170116184028385.jpg.chip.jpg\n",
      "Missing image: 24_0_1_20170116220224657.chip.jpg\n",
      "Missing image: 44_1_4_20170116235150272.pg.chip.jpg\n",
      "Unlisted image: 24_0_1_20170116220224657 .jpg.chip.jpg\n",
      "Misnamed image: 39_1_20170116174525125.jpg.chip.jpg\n",
      "Unlisted image: 61_1_20170109150557335.jpg.chip.jpg\n",
      "Misnamed image: 55_0_0_20170116232725357jpg.chip.jpg\n",
      "Misnamed image: 61_1_20170109142408075.jpg.chip.jpg\n",
      "Unlisted image: 53_1_0_20170116184028385.jpg.chip.jpg\n",
      "Unlisted image: 44_1_4_20170116235150272.jpg.chip.jpg\n",
      "\n",
      "Issues found: 11\n",
      "Matching images: 23701\n"
     ]
    }
   ],
   "source": [
    "from os import listdir, path\n",
    "\n",
    "directory = 'UTKFace'  # directory with images\n",
    "landmarks_file = 'landmark_list_concatenated.txt'  # list of images with landmarks\n",
    "probs = 0  # issues found\n",
    "matches = 0  # matching files found\n",
    "\n",
    "with open(landmarks_file, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "images = [line.split()[0] + \".chip.jpg\" for line in lines]\n",
    "image_set = set()\n",
    "for image in images:\n",
    "    file = path.join(directory, image)\n",
    "    if path.exists(file):\n",
    "        image_set.add(image)\n",
    "    else:\n",
    "        print(\"Missing image:\", image)\n",
    "        probs += 1\n",
    "\n",
    "# iterate over files in that directory\n",
    "for filename in listdir(directory):\n",
    "    f = path.join(directory, filename)\n",
    "    # checking if it is a file\n",
    "    if filename not in image_set:\n",
    "        print(\"Unlisted image:\", filename)\n",
    "        probs += 1\n",
    "    else:\n",
    "        splitname: list[str] = filename.split(\".\")[0].split(\"_\")\n",
    "        if len(splitname) != 4 or int(splitname[0]) < 1 or int(splitname[0]) > 200 or int(splitname[1]) > 1 or int(splitname[2]) > 4 or not splitname[3].isdigit():\n",
    "            print(\"Misnamed image:\", filename)\n",
    "            probs += 1\n",
    "        else:\n",
    "            matches += 1\n",
    "print(\"\\nIssues found:\", probs)\n",
    "print(\"Matching images:\", matches)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see that most of the listed images are missing metadata fields or have minor typos such as missing a period/character or an extraneous space character. And when that is the case, the image is listed twice: as a \"missing image\" and as an \"unlisted image\". The following script will apply the corrections to the landmark file, yielding a new file named `landmark_list_corrected.txt`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrections successfully applied to 'landmark_list_corrected.txt'\n"
     ]
    }
   ],
   "source": [
    "if path.exists('landmark_list_concatenated.txt'):\n",
    "\n",
    "    with open('landmark_list_concatenated.txt', 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    # Correcting specific lines of the spreadsheet so they match the actual image names\n",
    "    lines[8512] = lines[8512].replace(\"61_1_20170109142408075.jpg\", \"61_1_1_20170109142408075.jpg\")  # Missing gender\n",
    "    lines[8513] = lines[8513].replace(\"61_3_20170109150557335.jpg\", \"61_1_3_20170109150557335.jpg\")  # Missing gender\n",
    "    lines[13951] = lines[13951].replace(\"53__0_20170116184028385.jpg\", \"53_1_0_20170116184028385.jpg\")  # Missing gender\n",
    "    lines[20080] = lines[20080].replace(\"39_1_20170116174525125.jpg\", \"39_1_1_20170116174525125.jpg\")  # Missing gender\n",
    "    lines[20585] = lines[20585].replace(\"55_0_0_20170116232725357jpg\", \"55_0_0_20170116232725357.jpg\")  # Missing period\n",
    "    lines[20621] = lines[20621].replace(\"24_0_1_20170116220224657 .jpg\", \"24_0_1_20170116220224657.jpg\")  # Space in name\n",
    "    lines[20647] = lines[20647].replace(\"44_1_4_20170116235150272.pg\", \"44_1_4_20170116235150272.jpg\")  # Wrong extension\n",
    "\n",
    "    with open('landmark_list_corrected.txt', \"w\") as f:\n",
    "        f.writelines(lines)\n",
    "\n",
    "    print(\"Corrections successfully applied to 'landmark_list_corrected.txt'\")\n",
    "\n",
    "else:\n",
    "\n",
    "    print(\"ERROR: Could not find 'landmark_list_concatenated.txt'\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "However, we still need to correct 5 issues in image filenames; if using an Unix-compatible system (such as Linux, Mac or Windows with WSL), you can run the following shell script:\n",
    "\n",
    "```\n",
    "#!/usr/bin/env sh\n",
    "\n",
    "UTKZIP='UTKFace.tar.gz';\n",
    "UTKDIR='UTKFace';\n",
    "\n",
    "\tif [ ! -d \"$UTKDIR\" ]; then\n",
    "\t\tif [ -f \"$UTKZIP\" ]; then\n",
    "\t\t  echo \"Unzipping $UTKZIP to $UTKDIR...\"\n",
    "\t\t\ttar -xvf UTKFace.tar.gz 2>/dev/null\n",
    "\t\t\techo \"Done. Feel free to delete $UTKZIP.\"\n",
    "\t\telse\n",
    "\t\t  echo \"$UTKDIR directory not found. Please download $UTKZIP from https://gotil.la/3ziDcCX\"\n",
    "\t\tfi\n",
    "\tfi\n",
    "\tif [ -d \"$UTKDIR\" ]; then\n",
    "\t  echo \"$UTKDIR directory found.\"\n",
    "\t  cnt=0\n",
    "\t\tif [ -f \"$UTKDIR/24_0_1_20170116220224657 .jpg.chip.jpg\" ]; then\n",
    "\t\t    cnt=$((cnt+1))\n",
    "\t\t    echo \"Renaming 24_0_1_20170116220224657 .jpg.chip.jpg\\tto 24_0_1_20170116220224657.jpg.chip.jpg\"\n",
    "  \t\t\tmv \"$UTKDIR/24_0_1_20170116220224657 .jpg.chip.jpg\" \"$UTKDIR/24_0_1_20170116220224657.jpg.chip.jpg\"\n",
    "  \tfi\n",
    "\t\tif [ -f \"$UTKDIR/39_1_20170116174525125.jpg.chip.jpg\" ]; then\n",
    "\t\t    cnt=$((cnt+1))\n",
    "\t\t    echo \"Renaming 39_1_20170116174525125.jpg.chip.jpg\\tto 39_1_1_20170116174525125.jpg.chip.jpg\"\n",
    "  \t\t\tmv \"$UTKDIR/39_1_20170116174525125.jpg.chip.jpg\" \"$UTKDIR/39_1_1_20170116174525125.jpg.chip.jpg\"\n",
    "  \tfi\n",
    "\t\tif [ -f \"$UTKDIR/61_1_20170109150557335.jpg.chip.jpg\" ]; then\n",
    "\t\t    cnt=$((cnt+1))\n",
    "\t\t    echo \"Renaming 61_1_20170109150557335.jpg.chip.jpg\\tto 61_1_3_20170109150557335.jpg.chip.jpg\"\n",
    "  \t\t\tmv \"$UTKDIR/61_1_20170109150557335.jpg.chip.jpg\" \"$UTKDIR/61_1_3_20170109150557335.jpg.chip.jpg\"\n",
    "  \tfi\n",
    "\t\tif [ -f \"$UTKDIR/55_0_0_20170116232725357jpg.chip.jpg\" ]; then\n",
    "\t\t    cnt=$((cnt+1))\n",
    "\t\t    echo \"Renaming 55_0_0_20170116232725357jpg.chip.jpg\\tto 55_0_0_20170116232725357.jpg.chip.jpg\"\n",
    "  \t\t\tmv \"$UTKDIR/55_0_0_20170116232725357jpg.chip.jpg\" \"$UTKDIR/55_0_0_20170116232725357.jpg.chip.jpg\"\n",
    "  \tfi\n",
    "\t\tif [ -f \"$UTKDIR/61_1_20170109142408075.jpg.chip.jpg\" ]; then\n",
    "\t\t    cnt=$((cnt+1))\n",
    "\t\t    echo \"Renaming 61_1_20170109142408075.jpg.chip.jpg\\tto 61_1_1_20170109142408075.jpg.chip.jpg\"\n",
    "  \t\t\tmv \"$UTKDIR/61_1_20170109142408075.jpg.chip.jpg\" \"$UTKDIR/61_1_1_20170109142408075.jpg.chip.jpg\"\n",
    "  \tfi\n",
    "  \tif [ \"$cnt\" -eq 0 ]; then\n",
    "      echo \"Nothing to do; all files correctly named.\"\n",
    "  \tfi\n",
    "  else\n",
    "    \t  echo \"$UTKDIR directory not found.\"\n",
    "\tfi\n",
    "```\n",
    "\n",
    "Alternatively, you can apply the following corrections by hand:\n",
    "\n",
    "* `24_0_1_20170116220224657 .jpg.chip.jpg` -> `24_0_1_20170116220224657.jpg.chip.jpg` _(Space in filename)_\n",
    "* `55_0_0_20170116232725357jpg.chip.jpg` -> `55_0_0_20170116232725357.jpg.chip.jpg` _(Missing period)_\n",
    "* `61_1_20170109142408075.jpg.chip.jpg` -> `61_1_1_20170109142408075.jpg.chip.jpg` _(Missing gender)_\n",
    "* `61_1_20170109150557335.jpg.chip.jpg` -> `61_1_3_20170109150557335.jpg.chip.jpg` _(Missing race)_\n",
    "* `39_1_20170116174525125.jpg.chip.jpg` -> `39_1_1_20170116174525125.jpg.chip.jpg` _(Missing gender)_\n",
    "\n",
    "Once that is done, feel free to re-run the dataset validation script a few fields above to check that there ar eno more mismatches."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Analysing and Filtering the Data\n",
    "\n",
    "Now let's look at the data we have; the following table shows the breakdown of the dataset by gender, age and race (we will not use the datetime metadata field).\n",
    "\n",
    "#### Original UTKFace Dataset\n",
    "\n",
    "| **Gender/Age** | **Asian** | **Black** | **Indian** | **Other** |  **White** |  **Total** |\n",
    "|:---------------|----------:|----------:|-----------:|----------:|-----------:|-----------:|\n",
    "| **Female**     | **1,859** | **2,210** |  **1,715** |   **932** |  **4,601** | **11,317** |\n",
    "| 1 - 14         |       461 |       110 |        297 |       280 |        783 |      1,931 |\n",
    "| 15 - 24        |       414 |       346 |        383 |       277 |        667 |      2,087 |\n",
    "| 25 - 44        |       872 |     1,473 |        847 |       346 |      1,655 |      5,193 |\n",
    "| 45 - 64        |        39 |       205 |        146 |        22 |        798 |      1,210 |\n",
    "| 65 and over    |        73 |        76 |         42 |         7 |        698 |        896 |\n",
    "| **Male**       | **1,575** | **2,318** |  **2,261** |   **760** |  **5,477** | **12,391** |\n",
    "| 1 - 14         |       511 |        87 |        246 |       163 |        713 |      1,720 |\n",
    "| 15 - 24        |       137 |       246 |        175 |       121 |        486 |      1,165 |\n",
    "| 25 - 44        |       601 |     1,426 |      1,102 |       374 |      2,056 |      5,559 |\n",
    "| 45 - 64        |       179 |       400 |        649 |        97 |      1,560 |      2,885 |\n",
    "| 65 and over    |       147 |       159 |         89 |         5 |        662 |      1,062 |\n",
    "| **Total**      | **3,434** | **4,528** |  **3,976** | **1,692** | **10,078** | **23,708** |\n",
    "\n",
    "After review of some sample images and discussion with various teammembers, we decided to discard images for children (age < 15) and older adults (age ≥ 65) as well as those where the race was classified as \"Other\" for consistency. This reduced the dataset to the following:\n",
    "\n",
    "#### Filtered UTKFace Dataset\n",
    "\n",
    "| **Gender/Age** | **Asian** | **Black** | **Indian** | **White** |  **Total** |\n",
    "|:---------------|----------:|----------:|-----------:|----------:|-----------:|\n",
    "| **Female**     | **1,325** | **2,024** |  **1,376** | **3,120** |  **7,845** |\n",
    "| 15 - 24        |       414 |       346 |        383 |       667 |      2,087 |\n",
    "| 25 - 44        |       872 |     1,473 |        847 |     1,655 |      5,193 |\n",
    "| 45 - 64        |        39 |       205 |        146 |       798 |      1,210 |\n",
    "| **Male**       |   **917** | **2,072** |  **1,926** | **4,102** |  **9,017** |\n",
    "| 15 - 24        |       137 |       246 |        175 |       486 |      1,165 |\n",
    "| 25 - 44        |       601 |     1,426 |      1,102 |     2,056 |      5,559 |\n",
    "| 45 - 64        |       179 |       400 |        649 |     1,560 |      2,885 |\n",
    "| **Total**      | **2,242** | **4,096** |  **3,302** | **7,222** | **16,862** |\n",
    "\n",
    "We can use the `preselect_landmarks` function (below) to filter out images where the subject's age is under 15 or above 64 and their race is classified as 'other'. The script will produce a file called `ll_initial.txt` in the current directory listing the 16,862 images that fit that criteria. (Note that we specify the seed value through the `randomseed` parameter to enable reproducibility.)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import exit\n",
    "from os.path import exists\n",
    "\n",
    "def preselect_landmarks(landmarks_file: str, age=None, gender=None, race=None,\n",
    "                        *, log: bool = False, randomise: bool = False,\n",
    "                        randomseed=None, target=None, filename=None) -> None:\n",
    "    \"\"\" Preselect Landmarks\n",
    "\n",
    "    Iterates through an original file listing images and associated landmarks\n",
    "    applying the given filters and generates another file with the subset of\n",
    "    images that passed *all* filters.\n",
    "\n",
    "    :param landmarks_file: name of original landmark file (str, Required)\n",
    "    :param log: Whether to log why each image was discarded and to print a\n",
    "        summary message with the number of images filtered (Default: False)\n",
    "    :param target: (maximum) number of images to select based on the provided\n",
    "        filters. If defined, the function may output two files with suffixes:\n",
    "        • \"_filtered\": list of images which meet all filter criteria;\n",
    "        • \"_remainder\": list of images which do not meet filter criteria or\n",
    "            exceed target number;\n",
    "    :param randomise: shuffle landmarks before preselection? (Default: False)\n",
    "    :param randomseed: seed value (int) when randomising (Default: None)\n",
    "    :param age: tuple containing min (int) and max (int) values (Default: None)\n",
    "    :param gender: 'male' or 'female' (str, Default: None)\n",
    "    :param race: either a str with a single race or a list for multiple races,\n",
    "        values 'white', 'black', 'asian', 'indian' and 'other' (Default: None)\n",
    "    :param filename: filename for target files\n",
    "    :return: nothing, may print Errors, Warnings and log messages to stdout\n",
    "    \"\"\"\n",
    "    with open(landmarks_file, 'r') as file:\n",
    "        landmarks = file.readlines()\n",
    "\n",
    "    # Initialise maps\n",
    "    genders: dict[str: str] = {\n",
    "        '0': \"male\",\n",
    "        '1': \"female\"\n",
    "    }\n",
    "    races: dict[str: str] = {\n",
    "        '0': \"white\",\n",
    "        '1': \"black\",\n",
    "        '2': \"asian\",\n",
    "        '3': \"indian\",\n",
    "        '4': \"other\"\n",
    "    }\n",
    "\n",
    "    # Read parameters for valid filters and capture those for new filename\n",
    "    filters = []\n",
    "    if isinstance(age, tuple) and age[0] <= age[1]:\n",
    "        filters.append(str(age[0]) + \"-\" + str(age[1]))\n",
    "    if isinstance(gender, str) and gender in genders.values():\n",
    "        filters.append(gender)\n",
    "    if isinstance(race, str):\n",
    "        race = [race]\n",
    "    if isinstance(race, list) and all(r in races.values() for r in race):\n",
    "        filters.append(\"-\".join(race))\n",
    "\n",
    "    # Abort if no valid filters were found or invalid target\n",
    "    if len(filters) == 0:\n",
    "        print(\"Error: No valid filters to apply.\")\n",
    "        exit(1)\n",
    "    if target is not None and (not isinstance(target, int) or target < 1):\n",
    "        print(\"Error: Target needs to be greater than zero.\")\n",
    "        exit(1)\n",
    "\n",
    "    # Abort if files already exist with target name (avoid overwriting).\n",
    "    if filename:\n",
    "        filtered_landmarks_file = filename\n",
    "    else:\n",
    "        filtered_landmarks_file = landmarks_file.split(\".\")[0]\n",
    "        filtered_landmarks_file += \"_\" + \"_\".join(filters)\n",
    "    filtered_landmarks_file += \"_filtered\" if target else \"\"\n",
    "    filtered_landmarks_file += \".txt\"\n",
    "    if exists(filtered_landmarks_file):\n",
    "        print(f\"Error: File '{filtered_landmarks_file}' already exists in \"\n",
    "              f\"current directory; delete or rename and run script again.\")\n",
    "        exit(1)\n",
    "    if filename:\n",
    "        remainder_landmarks_file = filename\n",
    "    else:\n",
    "        remainder_landmarks_file = landmarks_file.split(\".\")[0]\n",
    "        remainder_landmarks_file += \"_\" + \"_\".join(filters)\n",
    "    remainder_landmarks_file += \"_remainder.txt\"\n",
    "    if target and exists(remainder_landmarks_file):\n",
    "        print(\n",
    "            f\"Error: File '{remainder_landmarks_file}' already exists in \"\n",
    "            f\"current directory; delete or rename and run script again.\")\n",
    "        exit(1)\n",
    "\n",
    "    if randomise:\n",
    "        if seed is not None:\n",
    "            seed(randomseed)\n",
    "        shuffle(landmarks)\n",
    "\n",
    "    filtered_landmarks: list[str] = []\n",
    "    remainder_landmarks: list[str] = []\n",
    "    for line in landmarks:\n",
    "        # Iterate over all lines in landmark file and apply filters\n",
    "        keep = True\n",
    "\n",
    "        # Retrieve metadata from filename\n",
    "        imagename = line.split()[0]\n",
    "        splitname: list[str] = imagename.split(\".\")[0].split(\"_\")\n",
    "        # 0 is presumed if no age is provided in metadata, so this may fail\n",
    "        # minimum age filters greater than 0.\n",
    "        line_age = int(splitname[0]) if len(splitname) > 0 else 0\n",
    "        # An image with no gender metadata will fail all gender filters\n",
    "        if len(splitname) > 1 and splitname[1] in genders:\n",
    "            line_gender = genders[splitname[1]]\n",
    "        else:\n",
    "            line_gender = \"\"\n",
    "        # An image without race metadata will fail any race filters\n",
    "        if len(splitname) > 2 and splitname[2] in races:\n",
    "            line_race = races[splitname[2]]\n",
    "        else:\n",
    "            line_race = \"\"\n",
    "\n",
    "        # Check if a given line passes *all* filters\n",
    "        if isinstance(age, tuple) and (line_age < age[0] or line_age > age[1]):\n",
    "            if log:\n",
    "                print(f\"Image {imagename} skipped due to age ({line_age}).\", )\n",
    "            keep = False\n",
    "        if isinstance(gender, str) and line_gender != gender:\n",
    "            if log:\n",
    "                print(f\"Image {imagename} skipped due to gender ({line_gender}).\", )\n",
    "            keep = False\n",
    "        if isinstance(race, list) and line_race not in race:\n",
    "            if log:\n",
    "                print(f\"Image {imagename} skipped due to race ({line_race}).\", )\n",
    "            keep = False\n",
    "\n",
    "        if keep and (target is None or target > len(filtered_landmarks)):\n",
    "            filtered_landmarks.append(line)\n",
    "            if log:\n",
    "                print(f\"Image {imagename} added to filtered list.\")\n",
    "        else:\n",
    "            remainder_landmarks.append(line)\n",
    "            if log and target:\n",
    "                print(f\"Image {imagename} added to remainder list.\")\n",
    "\n",
    "    if len(filtered_landmarks) == 0:\n",
    "        print(\"Warning: No images passed all filters.\")\n",
    "        exit(1)\n",
    "\n",
    "    with open(filtered_landmarks_file, 'w') as file:\n",
    "        file.writelines(filtered_landmarks)\n",
    "    if log:\n",
    "        print(len(filtered_landmarks),\n",
    "              \"filtered images saved to file\",\n",
    "              filtered_landmarks_file)\n",
    "\n",
    "    if target and len(remainder_landmarks) != 0:\n",
    "        with open(remainder_landmarks_file, 'w') as file:\n",
    "            file.writelines(remainder_landmarks)\n",
    "        if log:\n",
    "            print(len(remainder_landmarks),\n",
    "                  \"remainder images saved to file\",\n",
    "                  remainder_landmarks_file)\n",
    "\n",
    "\n",
    "# Selecting images for people of known races and with ages between 15-64.\n",
    "preselect_landmarks('landmark_list_corrected.txt', age=(15, 64),\n",
    "                    race=['asian', 'black', 'indian', 'white'], filename='ll_initial',\n",
    "                    randomise=True, randomseed=680780122122)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data into Training, Validation and Test datasets\n",
    "\n",
    "The plan is to train our models on 3 datasets with differing ratios of female/male images and then test their performance against malefemale-only, male-only and evenly-split datasets. This is the plan:\n",
    "\n",
    "![](Data_Preparation_Plan.png)\n",
    "\n",
    "First, let's run `preselect_landmarks` two more times to produce a file with 7,500 randomly-ordered males and another with 7,500 randomly-ordered females."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting 7,500 male images from the initial dataset\n",
    "preselect_landmarks('ll_initial.txt', gender=\"male\", target=7500, randomise=True, randomseed=680780122122)\n",
    "\n",
    "# Selecting 7,500 female images from the initial dataset\n",
    "preselect_landmarks('ll_initial_male_remainder.txt', gender=\"female\", target=7500, randomise=True, randomseed=680780122122)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make things easier to follow, let's import the `os` package and use it to rename the files to `ll_males.txt` and `ll_females.txt`, respectively. We can also delete the intermediary/additional files generated so far (and will do so at each step from now on)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Renaming the output files for clarity\n",
    "os.rename('ll_initial_male_filtered.txt', 'll_males.txt')\n",
    "os.rename('ll_initial_male_remainder_female_filtered.txt', 'll_females.txt')\n",
    "\n",
    "# Deleting intermediary files\n",
    "os.remove('landmark_list_concatenated.txt')\n",
    "os.remove('landmark_list_corrected.txt')\n",
    "os.remove('ll_initial.txt')\n",
    "os.remove('ll_initial_male_remainder.txt')\n",
    "os.remove('ll_initial_male_remainder_female_remainder.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can extract 750 lines (10%) from `ll_females.txt` and `ll_males.txt` and concatenate that into a single balanced test file called `ll_test_50-50_split.txt` with 1,500 images. We will keep all three files for our testing phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input files successfully concatenated as ll_test_50-50_split.txt\n"
     ]
    }
   ],
   "source": [
    "# Splitting the male data set into test (750 images) and training/validation (6,750 images)\n",
    "preselect_landmarks('ll_males.txt', filename=\"ll_males_test\", gender=\"male\", target=750, randomise=True, randomseed=680780122122)\n",
    "\n",
    "# Splitting the female data set into test (750 images) and training/validation (6,750 images)\n",
    "preselect_landmarks('ll_females.txt', filename=\"ll_females_test\", gender=\"female\", target=750, randomise=True, randomseed=680780122122)\n",
    "\n",
    "# Renaming the output files for clarity\n",
    "os.rename('ll_males_test_filtered.txt', 'll_test_males.txt')\n",
    "os.rename('ll_females_test_filtered.txt', 'll_test_females.txt')\n",
    "\n",
    "# Concatenating the male/female test images into a single dataset\n",
    "concatenate_files(\"ll_test_50-50_split.txt\", files=['ll_test_males.txt', 'll_test_females.txt'], delete=False)\n",
    "\n",
    "# Deleting intermediary files\n",
    "os.remove('ll_males.txt')\n",
    "os.remove('ll_females.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the remaining male/female data into Training (80%: 6,000 images) and Validation (10%: 750 images) sets, but we won't contatenate them just yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the male data set into training (6,000 images) and validation (750 images)\n",
    "preselect_landmarks('ll_males_test_remainder.txt', filename=\"ll_males_validation\", gender=\"male\", target=750)\n",
    "\n",
    "# Renaming the output files for clarity\n",
    "os.rename('ll_males_validation_filtered.txt', 'll_males_validation.txt')\n",
    "os.rename('ll_males_validation_remainder.txt', 'll_males_training.txt')\n",
    "\n",
    "# Deleting intermediary files\n",
    "os.remove('ll_males_test_remainder.txt')\n",
    "\n",
    "# Splitting the female data set into training (6,000 images) and validation (750 images)\n",
    "preselect_landmarks('ll_females_test_remainder.txt', filename=\"ll_females_validation\", gender=\"female\", target=750)\n",
    "\n",
    "# Renaming the output files for clarity\n",
    "os.rename('ll_females_validation_filtered.txt', 'll_females_validation.txt')\n",
    "os.rename('ll_females_validation_remainder.txt', 'll_females_training.txt')\n",
    "\n",
    "# Deleting intermediary files\n",
    "os.remove('ll_females_test_remainder.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to split both the male/female **training** sets into thirds so that we can compose our 3 separate cohorts (25-75 split, 50-50 split, 75-25 split)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input files successfully concatenated as ll_training_25-75_split.txt\n",
      "Input files successfully concatenated as ll_training_50-50_split.txt\n",
      "Input files successfully concatenated as ll_training_75-25_split.txt\n"
     ]
    }
   ],
   "source": [
    "# Spliting the male training dataset into 3 files with 2,000 images each\n",
    "preselect_landmarks('ll_males_training.txt', filename=\"ll_males_training_1\", gender=\"male\", target=2000)\n",
    "preselect_landmarks('ll_males_training_1_remainder.txt', filename=\"ll_males_training_2\", gender=\"male\", target=2000)\n",
    "\n",
    "# Renaming the output files for clarity\n",
    "os.rename('ll_males_training_1_filtered.txt', 'll_males_training_cohort_1.txt')\n",
    "os.rename('ll_males_training_2_filtered.txt', 'll_males_training_cohort_2.txt')\n",
    "os.rename('ll_males_training_2_remainder.txt', 'll_males_training_cohort_3.txt')\n",
    "\n",
    "# Deleting intermediary files\n",
    "os.remove('ll_males_training.txt')\n",
    "os.remove('ll_males_training_1_remainder.txt')\n",
    "\n",
    "# Spliting the female training dataset into 3 files with 2,000 images each\n",
    "preselect_landmarks('ll_females_training.txt', filename=\"ll_females_training_1\", gender=\"female\", target=2000)\n",
    "preselect_landmarks('ll_females_training_1_remainder.txt', filename=\"ll_females_training_2\", gender=\"female\", target=2000)\n",
    "\n",
    "# Renaming the output files for clarity\n",
    "os.rename('ll_females_training_1_filtered.txt', 'll_females_training_cohort_1.txt')\n",
    "os.rename('ll_females_training_2_filtered.txt', 'll_females_training_cohort_2.txt')\n",
    "os.rename('ll_females_training_2_remainder.txt', 'll_females_training_cohort_3.txt')\n",
    "\n",
    "# Deleting intermediary files\n",
    "os.remove('ll_females_training.txt')\n",
    "os.remove('ll_females_training_1_remainder.txt')\n",
    "\n",
    "# 25:75 Training file: 1 female cohort + 3 male cohorts\n",
    "concatenate_files('ll_training_25-75_split.txt', files=['ll_females_training_cohort_3.txt', 'll_males_training_cohort_1.txt', 'll_males_training_cohort_2.txt', 'll_males_training_cohort_3.txt'])\n",
    "\n",
    "# 50:50 Training file: 2 female cohorts + 2 male cohorts\n",
    "concatenate_files('ll_training_50-50_split.txt', files=['ll_females_training_cohort_1.txt', 'll_females_training_cohort_2.txt', 'll_males_training_cohort_1.txt', 'll_males_training_cohort_2.txt'])\n",
    "\n",
    "# 75:25 Training file: 3 female cohorts + 1 male cohort\n",
    "concatenate_files('ll_training_75-25_split.txt', files=['ll_females_training_cohort_1.txt', 'll_females_training_cohort_2.txt', 'll_females_training_cohort_3.txt','ll_males_training_cohort_3.txt'])\n",
    "\n",
    "# Deleting intermediary files\n",
    "os.remove('ll_females_training_cohort_1.txt')\n",
    "os.remove('ll_females_training_cohort_2.txt')\n",
    "os.remove('ll_females_training_cohort_3.txt')\n",
    "os.remove('ll_males_training_cohort_1.txt')\n",
    "os.remove('ll_males_training_cohort_2.txt')\n",
    "os.remove('ll_males_training_cohort_3.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do the same with the male/female **validation** sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input files successfully concatenated as ll_validation_25-75_split.txt\n",
      "Input files successfully concatenated as ll_validation_50-50_split.txt\n",
      "Input files successfully concatenated as ll_validation_75-25_split.txt\n"
     ]
    }
   ],
   "source": [
    "# Spliting the male validation dataset into 3 files with 250 images each\n",
    "preselect_landmarks('ll_males_validation.txt', filename=\"ll_males_validation_1\", gender=\"male\", target=250)\n",
    "preselect_landmarks('ll_males_validation_1_remainder.txt', filename=\"ll_males_validation_2\", gender=\"male\", target=250)\n",
    "\n",
    "# Renaming the output files for clarity\n",
    "os.rename('ll_males_validation_1_filtered.txt', 'll_males_validation_cohort_1.txt')\n",
    "os.rename('ll_males_validation_2_filtered.txt', 'll_males_validation_cohort_2.txt')\n",
    "os.rename('ll_males_validation_2_remainder.txt', 'll_males_validation_cohort_3.txt')\n",
    "\n",
    "# Deleting intermediary files\n",
    "os.remove('ll_males_validation.txt')\n",
    "os.remove('ll_males_validation_1_remainder.txt')\n",
    "\n",
    "# Spliting the female validation dataset into 3 files with 250 images each\n",
    "preselect_landmarks('ll_females_validation.txt', filename=\"ll_females_validation_1\", gender=\"female\", target=250)\n",
    "preselect_landmarks('ll_females_validation_1_remainder.txt', filename=\"ll_females_validation_2\", gender=\"female\", target=250)\n",
    "\n",
    "# Renaming the output files for clarity\n",
    "os.rename('ll_females_validation_1_filtered.txt', 'll_females_validation_cohort_1.txt')\n",
    "os.rename('ll_females_validation_2_filtered.txt', 'll_females_validation_cohort_2.txt')\n",
    "os.rename('ll_females_validation_2_remainder.txt', 'll_females_validation_cohort_3.txt')\n",
    "\n",
    "# Deleting intermediary files\n",
    "os.remove('ll_females_validation.txt')\n",
    "os.remove('ll_females_validation_1_remainder.txt')\n",
    "\n",
    "# 25:75 Validation file: 1 female cohort + 3 male cohorts\n",
    "concatenate_files('ll_validation_25-75_split.txt', files=['ll_females_validation_cohort_3.txt', 'll_males_validation_cohort_1.txt', 'll_males_validation_cohort_2.txt', 'll_males_validation_cohort_3.txt'])\n",
    "\n",
    "# 50:50 Validation file: 2 female cohorts + 2 male cohorts\n",
    "concatenate_files('ll_validation_50-50_split.txt', files=['ll_females_validation_cohort_1.txt', 'll_females_validation_cohort_2.txt', 'll_males_validation_cohort_1.txt', 'll_males_validation_cohort_2.txt'])\n",
    "\n",
    "# 75:25 Validation file: 3 female cohorts + 1 male cohort\n",
    "concatenate_files('ll_validation_75-25_split.txt', files=['ll_females_validation_cohort_1.txt', 'll_females_validation_cohort_2.txt', 'll_females_validation_cohort_3.txt','ll_males_validation_cohort_3.txt'])\n",
    "\n",
    "# Deleting intermediary files\n",
    "os.remove('ll_females_validation_cohort_1.txt')\n",
    "os.remove('ll_females_validation_cohort_2.txt')\n",
    "os.remove('ll_females_validation_cohort_3.txt')\n",
    "os.remove('ll_males_validation_cohort_1.txt')\n",
    "os.remove('ll_males_validation_cohort_2.txt')\n",
    "os.remove('ll_males_validation_cohort_3.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "We now have the following files ready for training, validation and testing:\n",
    "\n",
    "#### Training\n",
    "* 25% Female + 75% Male: `ll_training_25-75_split.txt` (8,000 lines)\n",
    "* 50% Female + 50% Male: `ll_training_50-50_split.txt` (8,000 lines)\n",
    "* 75% Female + 25% Male: `ll_training_75-25_split.txt` (8,000 lines)\n",
    "\n",
    "#### Validation\n",
    "* 25% Female + 75% Male: `ll_validation_25-75_split.txt` (1,000 lines)\n",
    "* 50% Female + 50% Male: `ll_validation_50-50_split.txt` (1,000 lines)\n",
    "* 75% Female + 25% Male: `ll_validation_75-25_split.txt` (1,000 lines)\n",
    "\n",
    "#### Testing\n",
    "* 100% Female: `ll_test_females.txt` (750 lines)\n",
    "* 100% Male: `ll_test_males.txt` (750 lines)\n",
    "* 50% Female + 50% Male: `ll_test_50-50_split.txt` (1,500 lines)\n",
    "\n",
    "## Models\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
