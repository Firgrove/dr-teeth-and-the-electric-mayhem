{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the Network\n",
    "\n",
    "Now that all the networks have been successfully trained, their models and training data in folders models, model_scores and model_infos we can commence testing.\n",
    "Each model will be tested on a 50-50 split of male to female testing data, soely male testing set and soely female testing set to compare between each other.\n",
    "\n",
    "First we will load all the models into memory, this is simply done by insert them all into a list and then initialising a model and then loading each file into that subsequent model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Adding in model names\n",
    "model_names = [\"convNN2_ll_training_50-50_split.txt_batch32_ep50_lr0.0001.pt\", \"convNN2_ll_training_27-75_split.txt_batch32_ep50_lr0.0001.pt\", \"convNN2_ll_training_75-25_split.txt_batch32_ep50_lr0.0001.pt\",\n",
    "        \"convNN2_ll_training_27-75_split.txt_batch32_ep50_lr0.0001.pt\", \"dense_ll_training_50-50_split.txt_batch32_ep50_lr0.0001.pt\", \"dense_ll_training_25-75_split.txt_batch32_ep50_lr0.0001.pt\",\n",
    "        \"dense_ll_training_75-25_split.txt_batch32_ep50_lr0.0001.pt\", \"resnet34_ll_training_50-50_split.txt_batch32_ep50_lr0.0001.pt\", \"resnet34_ll_training_25-75_split.txt_batch32_ep50_lr0.0001.pt\",\n",
    "        \"resnet34_ll_training_75-25_split.txt_batch32_ep50_lr0.0001.pt\"]\n",
    "\n",
    "models = [convNN2(), convNN2(), convNN2(), denseNN(), denseNN(), denseNN(), resnet34(), resnet34(), resnet34()]\n",
    "\n",
    "for name, model in zip(model_names, models):\n",
    "    model.load_state_dict(torch.load(\"./models/\" + name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "source": [
    "Once we have done this we can now calculate the scores of each model on each test set, this should compute the mean error and std and return it as a tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    print(model.__class__.__name__)\n",
    "    print(\"50-50 test file \" + evaluate(model, \"./ll_test_50-50\", \"cpu\"))\n",
    "    print(\"male test file \" + evaluate(model, \"./ll_test_males\", \"cpu\"))\n",
    "    print(\"female test file \" + evaluate(model, \"./ll_test_females\", \"cpu\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error for the convNN2 is much higher than the the other two models, this is due to the simplicity of the model. \n",
    "While we can see that ResNet34 outperformed DesneNet121 with a significant reduction in error between the two.\n",
    "Both models had higher error in females for identifing landmarks for both genders, as expected started this project.\n",
    "\n",
    "Both models performed best overall on balanced data sets, though this difference was very slight.\n",
    "It also shows that a higher proportional of females or males in the dataset does not neccesarily result in a lower error for each respective gender, but the change in error was quite minimal \n",
    "meaning we can discard the bias in the dataset as a source of the bias between males and females.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can generate graphs for the change in mean error and standard deviation during training, and how it progressed over the iterations.\n",
    "\n",
    "All the extra saved data, when the model is loaded in and plotted on two seperate graphs.\n",
    "When loading in the model scores file, we need to parse this data to make it useful to us and is split into a list by using ',' as dividers.\n",
    "While the model infos are already presented in a json file and ready to read in simply, this gives us the iteration and mean or std of the saved model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for model in models:\n",
    "    epoch = []\n",
    "    error = []\n",
    "    std = []\n",
    "    m_nopt = args.model.split(\".pt\")\n",
    "    with open(\"./model_scores/\" + m_nopt[0] + \".csv\") as file:\n",
    "        for line in file:\n",
    "            scores = line.split(\",\")   \n",
    "            epoch.append(float(scores[0]))\n",
    "            error.append(float(scores[1]))\n",
    "            std.append(float(scores[2]))\n",
    "    \n",
    "    file = open(\"./model_infos/\" + m_nopt[0] + \".json\")\n",
    "    model_info = json.load(file)\n",
    "\n",
    "    plt.plot(epoch, error)\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Mean Error\")\n",
    "    plt.title('Error change during training')\n",
    "\n",
    "    plt.scatter([model_info[\"iteration\"]], [model_info[\"mean\"]], color = 'red')\n",
    "    plt.gca().legend(('Validation Error','Best performing iteration'))\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(epoch, std)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Standard Deviation\")\n",
    "    plt.title('STD change during training')\n",
    "    plt.scatter([model_info[\"iteration\"]], [model_info[\"std\"]], color = 'red')\n",
    "    plt.gca().legend(('Validation Error','Best performing iteration'))\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the graphs we can see that all error all std over time rapidly decreases within the first few iterations as the weights start off as zero, and the furthest possible away from the correct points (chin, nose and left eye) as possible.\n",
    "Both the ConvNN2 and DenseNet seem to oscillate between certain points and do not converge to a single point like the Resnet34 does, this seems to indicate that they have not obtained the most optimal model.\n",
    "\n",
    "We can visually check how accurate and close the predictions of the landmarks are on an image, comparing these against the input landmarks used by the model to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def generate_images(train_dataloader, axs_flat):\n",
    "    with torch.no_grad():\n",
    "            for i, (image, _, _, _, labels) in enumerate(train_dataloader):\n",
    "                output = model(image)\n",
    "                output = output.reshape(3,2)\n",
    "                image = image.squeeze()\n",
    "                image = image.permute(1, 2, 0)    #Default was 3,200,200\n",
    "                im = axs_flat[i].imshow(image)\n",
    "                x = np.array(range(200))\n",
    "\n",
    "                # Finding landmarks for chin, nose and eye this txt file for each image\n",
    "                land_idx = [8, 30, 39]\n",
    "                labels = labels.squeeze()\n",
    "                labels = labels[land_idx, :]\n",
    "                #ax.scatter(output[:,0], output[:,1], linewidth=2, color='red')\n",
    "                axs_flat[i].scatter(output[:,0], output[:,1], linewidth=2, color='c', s = 5)\n",
    "                axs_flat[i].scatter(labels[:,0], labels[:,1], linewidth=2, color='m', s = 5)\n",
    "\n",
    "UTKFace = CustomImageDataset(\"./test_output_images\", 'UTKFace')\n",
    "train_dataloader = DataLoader(UTKFace, \n",
    "                                    batch_size=1, \n",
    "                                    shuffle=False)\n",
    "\n",
    "for model in models:\n",
    "    print(model.__class__.__name__)\n",
    "    fig, axs = plt.subplots(2,5, figsize=(20,10))\n",
    "    axs_flat = axs.flatten()\n",
    "\n",
    "    generate_images(train_dataloader, axs_flat)\n",
    "    #plt.subplots_adjust(wspace=0, hspace=0)\n",
    "    fig.legend(('Predicted output','Expected output'))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis\n",
    "\n",
    "As we can see the basic convolutional neural network essentially predicts the same three points for every single image, since that gives the best average mean error for the model\n",
    "as the model is underfitting. Since it doesn't have enough layers, depth or complexity in order to compute, recognise and plots the landmarks on different features of the face. \n",
    "\n",
    "Currently the model produces a very high mean error 54.377 and 54.895 for females and males, and in a 200x200 image this is very far of. \n",
    "\n",
    "\n",
    "There is not much that can be done to improve on since the error may reduce slightly as more layers are added, but since it is a basic model the error would start going back soon after adding more layers\n",
    "due to the problem of vanishing gradient and potentially overfitting of the model. This would be a problem as when calculating the product of the derivative for the weights during backpropogation\n",
    "decreases to zero until the partial derivative of the loss function approaches zero and the partial derivative disappears.\n",
    "\n",
    "One of the main reason resnet and densenet were developed was to attempt to solve this vanishing gradient issue in neural networks, and as such will be more appropriate in this example.\n",
    "Thus, convNN2 will not be considered when evaluating our hypothesis.\n",
    "\n",
    "This basic neural net was useful in testing the limits of the possible calculations for a neural network in performing a more specialised task, additionally it forced us to explore other\n",
    "neural network models that were more useful. Additionally, it gave us an insight into the amount of work and research done into various nets and trying to improve them.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both ResNet34 and DenseNet121 vastly outperformed convNN2 and get significantly lower average mean error and standard deviation.\n",
    "Their errors on different datasets can be seen below\n",
    "##### ResNet34 Test Data\n",
    "![ResNet34 Test Data](jupyter_images/resnet34table.jpg) \n",
    "##### DenseNet121 Test Data\n",
    "![DenseNet121 Test Data](jupyter_images/densenet121table.jpg)\n",
    "\n",
    "From the tables we can see that ResNet had an error about 45% lower than DenseNet, and was a lot more sensitive to data bias from the data sets.\n",
    "The DenseNet has regardless of data set bias higher mean error for women than men, while for ResNet this error flipped with datasets that utilised a larger subset of women than men.\n",
    "\n",
    "\n",
    "If we look at a graph for both models to get a better understand of what is happening during training\n",
    "\n",
    "![Both Models Mean Error Change](jupyter_images/modelgraphs.jpg)\n",
    "\n",
    "ResNet mean error converges to a single while DenseNet continues oscillating and does not converge.\n",
    "This indicates that DenseNet had some issue during training and did not output a very optimal model, there is a potential of having vanishing gradients as the number of layers is more than double the amount in ResNet and it doesn't skip connections. The task of identify only three landmarks in a face, is a relatively simple task in terms of image classification and potentially the amount of layer used for DenseNet is way more than required since ResNet performs well with a much lower amount of layers.\n",
    "DenseNet allows connections to any node to travel to any other node in the fully connected layers which are contained in denseblocks, but the input is not connected to the output or final denseblocks which could cause this problem of vanishing gradients.\n",
    "\n",
    "Another issue may be due to underfitting of the model, which may be experimented with by increasing the amount of layers in the network in the future. If there is an increase or no change in mean error, it would highlight that vanishing gradients is at play and the number of layers must be reduced instead.\n",
    "\n",
    "Differing amounts and types of pooling can be experimented with in the future as ResNet uses max pooling while DenseNet uses more average pooling. This could reduce the fidelity and reduce the visibility of contours and features of the face, and as seen by the image output our model performed better on high resolution, sharper images with higher constrast. Additionally, max pooling sharpens and image increasing the constrast making it easier for our model to identify landmarks in the image while average pooling smooths out an image reducing contrast.\n",
    "\n",
    "\n",
    "Those all of our testing and experiements indicate as suggested by the literature biases in data set is not neccesarily the root cause of discrepancies found between men and women in image classification tasks.\n",
    "In the data, the change in bias causes only slightly changes to the mean error for both men and women for a less sensitive model like DenseNet the mean error for females is always higher. But with ResNet using a higher female biased data set did cause the mean error for females to be lower than males, though this error was still higher than the mean error for males when using a male biased data set, suggesting that neural network models do struggle more so with females than males as expected.\n",
    "As stated by papers the issue is in the differing facial structure and subtultey of facial for women which often quite difficult for neural networks to identify.\n",
    "DenseNet is a model classically used for image classification yet this model had certain issues, potentially indicating that the model is not quite complex enough and failing due to the more intricate features of female faces possibly due to vanishing gradient or underfiting during training.\n",
    "\n",
    "This project may of highlighted the three landmarks choosen as the chin, nose and eye as potential features that work for identifying both female and males with a low disparity in error between genders and could potentially be utilised in future image classification and facial recognition software and projects. Though further testing is required as this only looks at a small section of the supplied landmarks, and not the whole face or various sections of the face. Once more landmarks are included the small error from our models may increase exponentially and no longer be feasible to use. Also once more landmarks are implemented more complicated models would with more fine tuned features would be required to minimize loss and be sufficient to test our hypothesis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Future Work\n",
    "Some future work that may be performed is to eliminate other facial features from the list of potential causes for unfair results between males and females. \n",
    "\n",
    "Investigate if the unfair accuracy stems from a Neural Network’s lack of capacity to handle excessive number of facial features.\n",
    "\n",
    "Investigate the minimal number of facial features necessary to perform face recognition fairly.​\n",
    "\n",
    "Investigate to what extent data can be biased but still achieve face recognition fairly on the identified ideal facial features.\n",
    "\n",
    "Investigate if fairness is still achieved in our results for individual races."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
